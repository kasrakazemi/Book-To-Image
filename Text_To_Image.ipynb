{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"https://github.com/woctezuma/stable-diffusion-colab/blob/main/stable_diffusion.ipynb","timestamp":1714298057485}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["%pip install --quiet --upgrade diffusers transformers accelerate mediapy peft"],"metadata":{"id":"ufD_d64nr08H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","Load Summarized Data"],"metadata":{"id":"8NxsZCv64wxQ"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Q5ONnEsi4wIR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np"],"metadata":{"id":"uFpvQYZS49J6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(\"/content/drive/MyDrive/Data Co lab/dataset_summarized.csv\")"],"metadata":{"id":"NomYApKs49AD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.iloc[0]['shortened_summary_sumy_lsa']"],"metadata":{"id":"hpTP95Uo5AYp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-NNh9gFl5Boa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","Stable diffiusion Xl\n","\n","\n","---\n","\n"],"metadata":{"id":"sf6Abl6I6GCD"}},{"cell_type":"code","source":["import mediapy as media\n","import random\n","import sys\n","import torch\n","\n","from diffusers import DiffusionPipeline, TCDScheduler\n","from huggingface_hub import hf_hub_download\n","\n","# Choose among 1, 2, 4 and 8:\n","num_inference_steps = 8\n","\n","base_model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n","repo_name = \"ByteDance/Hyper-SD\"\n","plural = \"s\" if num_inference_steps > 1 else \"\"\n","ckpt_name = f\"Hyper-SDXL-{num_inference_steps}step{plural}-lora.safetensors\"\n","device = \"cuda\"\n","\n","pipe = DiffusionPipeline.from_pretrained(base_model_id, torch_dtype=torch.float16, variant=\"fp16\").to(device)\n","pipe.load_lora_weights(hf_hub_download(repo_name, ckpt_name))\n","pipe.fuse_lora()\n","pipe.scheduler = TCDScheduler.from_config(pipe.scheduler.config)"],"metadata":{"id":"bG2hkmSEvByV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = \"thorn, fone bone, phoney and smiley make it to the front wall, where thorn reunites with granma ben.fone bone and thorn quarrel on the subject of the crown of horns: fone believes that it will destroy everything because thorn has a piece of the locust inside herself, whereas thorn believes that her mother would not have told her to find it if she moonwort had known that it would destroy everything.thorn goes to look for the crown of horns and must leave fone bone behind.as the bone cousins, thorn, and granma ben leave for barrelhaven to bury lucius, phoney is given his hay wagon that he had lost earlier in the volume which still has the treasure in it.fone bone says goodbye to granma, to the red dragon, to the insect ted, and to thorn.thorn then wakes up, and at this point readers learn that tarsils soldiers had beaten thorn and fone bone brutally and thrown them into a dungeon.fone bone looks for thorn on bartlebys back.thorn leaves without fone bone by facing an army of their enemies and flying over them, forcing fone bone to hide under bartleby again.at the same time that this is occurring, fone bone arrives to help thorn and attempts to touch the crown of horns himself.thorn gives fone bone a basket of biscuits and honey, revealing that she had kept it aside until now in hope that he would change his mind and stay.fone mentions the possibility that in using the crown, thorn will destroy both the locust and herself mdash; shedding tears out of fear of thorns death, whereupon she promises not to use the crown of horns.fone then refuses to leave for boneville with phoney and smiley as hed promised.when they have gone, taneal, her brother, phoney, and smiley look into the others cell and find that thorn is comatose.they climb the ladder as fone and thorn are coming down, which results in a struggle.then thorn, in turn, breaks her promise to fone and leaves the group to search for the crown of horns, now with a lead as to its location.to find thorn while remaining hidden from the rat creatures, fone hides underneath bartleby, clinging to his stomach fur, suggesting the trick used by odysseus to conceal his men from polyphemus.fone and thorn sneak past roque ja in order to reach the dragon graveyard, but fail when roque ja sees them.saddened by this reminder of their first meeting, fone shares a hug with her and replies oh, i....ill never forget you thorn; i dont think i could.the chapter starts with briar, queen lunaria and lunarias husband the king at dragons stair, and because of the enemies attacking, thorn is given to her grandmother, rose harvestar, who is also known as granma ben.after lucius burial, phoney complains to fone bone about the snowflakes, and finally, the snow falls in a huge lump outside barrelhaven.\"\n","seed = random.randint(0, sys.maxsize)\n","\n","# Decrease eta (min: 0, max: 1.0) to get more details with multi-step inference:\n","eta = 0.2\n","\n","images = pipe(\n","    prompt = prompt,\n","    num_inference_steps = num_inference_steps,\n","    guidance_scale = 0.0,\n","    eta = eta,\n","    generator = torch.Generator(device).manual_seed(seed),\n","    ).images\n","\n","print(f\"Prompt:\\t{prompt}\\nSeed:\\t{seed}\")\n","media.show_images(images)\n","images[0].save(\"output.jpg\")"],"metadata":{"id":"AUc4QJfE-uR9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lAQaXzVM2yiW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","Stable diffiusion 2/1\n","\n","\n","---\n","\n"],"metadata":{"id":"L8mlgZBZBWWK"}},{"cell_type":"code","source":["!pip install Pillow\n","!pip install accelerate scipy safetensors"],"metadata":{"id":"FxZX1Tfi2zZV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from diffusers import StableDiffusionPipeline\n","from PIL import Image\n","\n","# Replace the model version with your required version if needed\n","pipeline = StableDiffusionPipeline.from_pretrained(\n","    \"stabilityai/stable-diffusion-2-1\", torch_dtype=torch.float16\n",")\n","\n","# Running the inference on GPU with cuda enabled\n","pipeline = pipeline.to('cuda')\n","\n","prompt = df.iloc[3]['shortened_summary_sumy_lsa']\n","\n","image = pipeline(prompt=prompt).images[0]\n"],"metadata":{"id":"qvKprI116uyt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from IPython.display import display\n","display(image)"],"metadata":{"id":"pZtB9Xp76uwb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"T1Hr41AA6uot"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","Stable diffiusion Xl\n","\n","\n","---\n","\n"],"metadata":{"id":"hzaaXGEgEWSB"}},{"cell_type":"code","source":["import torch\n","from diffusers import StableDiffusionXLPipeline\n","\n","pipe = StableDiffusionXLPipeline.from_pretrained(\n","    \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16\n",")\n","pipe = pipe.to(\"cuda\")\n","\n","prompt = df.iloc[3]['shortened_summary_sumy_lsa']\n","image = pipe(prompt).images[0]"],"metadata":{"id":"v1rUfMsREXz3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image.save(\"/content/drive/MyDrive/Data Colab/The Shaughraun.jpg\")"],"metadata":{"id":"GaQdGUCJHhnP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image"],"metadata":{"id":"AQPgyZteEYWu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5arT_coTEYUJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6imgN4iBEYRS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install --upgrade openai"],"metadata":{"id":"X2red1E6C5oL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["api_keyy = 'LQ4pz3IUiTwM7SU'"],"metadata":{"id":"Pw8y5ihAC5km"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import openai\n","\n","openai.my_api_key = api_keyy\n"],"metadata":{"id":"Cz8KKhBYC5h_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import requests\n","import json\n","import os\n","\n","openai_api_key = api_keyy\n","if openai_api_key is None:\n","    raise ValueError(\"OpenAI API key is not set in environment variables.\")\n","\n","url = \"https://api.openai.com/v1/chat/completions\"\n","\n","headers = {\n","    \"Content-Type\": \"application/json\",\n","    \"Authorization\": f\"Bearer {openai_api_key}\"\n","}\n","\n","data = {\n","    \"model\": \"gpt-3.5-turbo\",\n","    \"messages\": [\n","        {\n","            \"role\": \"system\",\n","            \"content\": \"You are a helpful assistant.\"\n","        },\n","        {\n","            \"role\": \"user\",\n","            \"content\": \"Hello!\"\n","        }\n","    ]\n","}\n","\n","response = requests.post(url, headers=headers, json=data)\n","\n","# Check if the request was successful\n","if response.status_code == 200:\n","    print(\"Response from OpenAI:\", response.json())\n","    print('\\n')\n","    print(response.json()['choices'][0]['message']['content'])\n","else:\n","    print(\"Error:\", response.status_code, response.text)"],"metadata":{"id":"pEpdxlSTDlX_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"PrHB-fL2DlUt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gBiEAtANDlSg"},"execution_count":null,"outputs":[]}]}